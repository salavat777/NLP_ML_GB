{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (4.3.2)\r\n",
      "Requirement already satisfied: tqdm in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (4.66.1)\r\n",
      "Requirement already satisfied: stop_words in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (2018.7.23)\r\n",
      "Requirement already satisfied: pymorphy2 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (0.9.1)\r\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from gensim) (1.26.0)\r\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from gensim) (1.11.3)\r\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from gensim) (6.4.0)\r\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from pymorphy2) (0.7.2)\r\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from pymorphy2) (2.4.417127.4579844)\r\n",
      "Requirement already satisfied: docopt>=0.6 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from pymorphy2) (0.6.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim tqdm stop_words pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-telegram-bot==13.3 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (13.3)\r\n",
      "Requirement already satisfied: certifi in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from python-telegram-bot==13.3) (2023.7.22)\r\n",
      "Requirement already satisfied: tornado>=5.1 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from python-telegram-bot==13.3) (6.3.3)\r\n",
      "Requirement already satisfied: APScheduler==3.6.3 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from python-telegram-bot==13.3) (3.6.3)\r\n",
      "Requirement already satisfied: pytz>=2018.6 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from python-telegram-bot==13.3) (2023.3.post1)\r\n",
      "Requirement already satisfied: setuptools>=0.7 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from APScheduler==3.6.3->python-telegram-bot==13.3) (68.0.0)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from APScheduler==3.6.3->python-telegram-bot==13.3) (1.16.0)\r\n",
      "Requirement already satisfied: tzlocal>=1.2 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from APScheduler==3.6.3->python-telegram-bot==13.3) (5.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-telegram-bot==13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandarallel in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (1.6.5)\n",
      "Requirement already satisfied: dill>=0.3.1 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from pandarallel) (0.3.7)\n",
      "Requirement already satisfied: pandas>=1 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from pandarallel) (2.1.1)\n",
      "Requirement already satisfied: psutil in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from pandarallel) (5.9.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from pandas>=1->pandarallel) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1->pandarallel) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (1.3.1)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from scikit-learn) (1.26.0)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from scikit-learn) (1.11.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/samurai/anaconda3/envs/chat_bot/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge python-annoy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xAhRcgdAVJzn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from telegram.ext  import Updater, CommandHandler, MessageHandler, Filters\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "    \n",
    "tqdm.pandas()\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "import re\n",
    "\n",
    "def get_num_lines(file_path):\n",
    "    fp = open(file_path, \"r+\")\n",
    "    buf = mmap.mmap(fp.fileno(), 0)\n",
    "    lines = 0\n",
    "    while buf.readline():\n",
    "        lines += 1\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачать файл Otvety.txt по ссылке  (1,7G)\n",
    "# https://drive.google.com/file/d/1DQL9ybca4USImUDaxxHmkIZNmClKBtKG/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 warning 16008\n",
      "2 warning 24252\n",
      "3 warning 28063\n",
      "4 warning 63206\n",
      "5 warning 67461\n",
      "6 warning 67998\n",
      "7 warning 75922\n",
      "8 warning 81640\n",
      "9 warning 89370\n",
      "10 warning 107202\n",
      "11 warning 110664\n",
      "12 warning 115360\n",
      "13 warning 120971\n",
      "14 warning 128226\n",
      "15 warning 130296\n",
      "16 warning 151831\n",
      "17 warning 155515\n",
      "18 warning 159384\n",
      "19 warning 171829\n",
      "20 warning 174883\n",
      "21 warning 178879\n",
      "22 warning 179555\n",
      "23 warning 180490\n",
      "24 warning 181882\n",
      "25 warning 185220\n",
      "26 warning 279098\n",
      "27 warning 282378\n",
      "28 warning 284824\n",
      "29 warning 285086\n",
      "30 warning 291145\n",
      "31 warning 320844\n",
      "32 warning 331618\n",
      "33 warning 339317\n",
      "34 warning 347842\n",
      "35 warning 353087\n",
      "36 warning 356344\n",
      "37 warning 358027\n",
      "38 warning 367174\n",
      "39 warning 370476\n",
      "40 warning 375469\n",
      "41 warning 389756\n",
      "42 warning 406089\n",
      "43 warning 409547\n",
      "44 warning 417512\n",
      "45 warning 431590\n",
      "46 warning 432454\n",
      "47 warning 443862\n",
      "48 warning 453486\n",
      "49 warning 454997\n",
      "50 warning 462469\n",
      "51 warning 463497\n",
      "52 warning 480454\n",
      "53 warning 480939\n",
      "54 warning 481799\n",
      "55 warning 491150\n",
      "56 warning 493268\n",
      "57 warning 498962\n",
      "500001\n"
     ]
    }
   ],
   "source": [
    "# Разделение файла вопросов-ответов на два файла, ограничим 500 тыс. строк\n",
    "question = False\n",
    "answer = False\n",
    "counter = 0\n",
    "i = 1\n",
    "#counter_ans = 0\n",
    "with open(\"question_test.txt\", \"w\") as fout_q:\n",
    "    with open(\"answers_test.txt\", \"w\") as fout_ans:\n",
    "        with open(\"Otvety.txt\", \"r\") as fin:\n",
    "            for line in fin:\n",
    "                if counter > 500000:\n",
    "                    break\n",
    "                if line.startswith(\"---\"):\n",
    "                    if not question and not answer:\n",
    "                        question = True\n",
    "                        answer = False\n",
    "                    else:\n",
    "                        print(f'{i} warning {counter}')\n",
    "                        question = False\n",
    "                        answer = False\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    counter += 1\n",
    "                    #print(counter)\n",
    "                    continue\n",
    "                if question and not answer:\n",
    "                    question_line = line\n",
    "                    #print(line)\n",
    "                    question = False\n",
    "                    answer = True\n",
    "                    continue\n",
    "                if answer and not question:\n",
    "                    fout_ans.write(line)\n",
    "                    fout_q.write(question_line)\n",
    "                    answer = False\n",
    "                    #print(line)\n",
    "                    continue\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "with open(\"answers_test.txt\", \"r\") as fin:\n",
    "    for line in fin:\n",
    "        if line == '\\n':\n",
    "            counter += 1\n",
    "        \n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "with open(\"question_test.txt\", \"r\") as fin:\n",
    "    for line in fin:\n",
    "        if line == '\\n':\n",
    "            counter += 1\n",
    "        \n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499943\n"
     ]
    }
   ],
   "source": [
    "print(get_num_lines(\"question_test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499943\n"
     ]
    }
   ],
   "source": [
    "print(get_num_lines(\"answers_test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qNovia_FVJz7"
   },
   "outputs": [],
   "source": [
    "# Препроцессинг текста\n",
    "def preprocess_txt(line):\n",
    "    \n",
    "    line = re.sub('<[^<]+?>', '', line) # удалить из входного текста все HTML-теги\n",
    "    line = re.sub(r'http\\S+', '', line) # удаляем из текста все URL и ссылки\n",
    "    line = re.sub('[^а-яА-ЯёЁ0-9\\s]', '', line) # убираем специальные символы: избавляемся от всего, что не является \"словами\"\n",
    "    line = re.sub(r'[^\\w\\s]', '', line) # удаляем из текста все знаки препинания\n",
    "    \n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    \n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132fdf06a38f462f9c4a5c6c021985b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Обработка текста вопросов\n",
    "\n",
    "sentences_q = []\n",
    "\n",
    "file_path_from = 'question_test.txt'\n",
    "file_path_to = 'question_test_sent.txt'\n",
    "\n",
    "if not os.path.isfile(file_path_to):\n",
    "    \n",
    "    N = get_num_lines(file_path_from)\n",
    "    with open(file_path_to, mode = 'w') as fileto:\n",
    "        with open(file_path_from) as filefrom:\n",
    "            for k in tqdm(range(N)):\n",
    "                line = filefrom.readline()\n",
    "                if line == '': break\n",
    "                spls = preprocess_txt(line)\n",
    "                sentences_q.append(spls)\n",
    "                fileto.write(' '.join(spls)+'\\n')\n",
    "    filefrom.close()\n",
    "    fileto.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "f32db27df42f4863a58d2d9996f088e3"
     ]
    },
    "id": "uvwpdubYVJz8",
    "outputId": "83dd0de8-4106-4dbc-c584-61c1a23cb9bd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418f7966aa8a494482d5844b3609e9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Обработка текста ответов\n",
    "\n",
    "sentences_ans = []\n",
    "\n",
    "file_path_from = 'answers_test.txt'\n",
    "file_path_to = 'answers_test_sent.txt'\n",
    "\n",
    "if not os.path.isfile(file_path_to):\n",
    "    \n",
    "    N = get_num_lines(file_path_from)\n",
    "    with open(file_path_to, mode = 'w') as fileto:\n",
    "        with open(file_path_from) as filefrom:\n",
    "            for k in tqdm(range(N)):\n",
    "                line = filefrom.readline()\n",
    "                if line == '': break\n",
    "                spls = preprocess_txt(line)\n",
    "                sentences_ans.append(spls)\n",
    "                fileto.write(' '.join(spls)+'\\n')\n",
    "    filefrom.close()\n",
    "    fileto.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7694199d961048e3aa21aa7e521539c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузить результат из файла ответов\n",
    "\n",
    "sentences_ans = []\n",
    "\n",
    "file_path_from = 'answers_test_sent.txt'\n",
    "if os.path.isfile(file_path_from):  \n",
    "    N = get_num_lines(file_path_from) \n",
    "    with open(file_path_from, mode = 'r') as filefrom:\n",
    "        for k in tqdm(range(N)):\n",
    "            line = filefrom.readline()\n",
    "            if line == '': break\n",
    "            sentences_ans.append(line.split())\n",
    "    filefrom.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cbff6db4324698acb15f78b9117554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузить результат из файла вопросов\n",
    "\n",
    "sentences_q = []\n",
    "\n",
    "file_path_from = 'question_test_sent.txt'\n",
    "if os.path.isfile(file_path_from):  \n",
    "    N = get_num_lines(file_path_from) \n",
    "    with open(file_path_from, mode = 'r') as filefrom:\n",
    "        for k in tqdm(range(N)):\n",
    "            line = filefrom.readline()\n",
    "            if line == '': break\n",
    "            sentences_q.append(line.split())\n",
    "    filefrom.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['хомячок'],\n",
       " ['вобщий', 'прикалывать', 'тема'],\n",
       " ['счастие',\n",
       "  'свалиться',\n",
       "  'хороший',\n",
       "  'пойти',\n",
       "  'милиция',\n",
       "  'заявить',\n",
       "  'находка',\n",
       "  'деньга',\n",
       "  'тероть',\n",
       "  'самый',\n",
       "  'интересный',\n",
       "  'неприменный',\n",
       "  'искать',\n",
       "  'поверьте',\n",
       "  'найти',\n",
       "  'видеть',\n",
       "  'подобный',\n",
       "  'нарваться',\n",
       "  'бабушка',\n",
       "  'помочий',\n",
       "  'внук',\n",
       "  'покупка',\n",
       "  'квартира',\n",
       "  'бандит',\n",
       "  'разговаривать',\n",
       "  'иначе',\n",
       "  'бабушка',\n",
       "  'милиция',\n",
       "  'выбор',\n",
       "  'шанс',\n",
       "  'подарок',\n",
       "  'выше',\n",
       "  'котрый',\n",
       "  'никто',\n",
       "  'спросить',\n",
       "  'хороший',\n",
       "  'отдать',\n",
       "  'хотяб',\n",
       "  '500',\n",
       "  'благотворительность',\n",
       "  'дабы',\n",
       "  'спугнуть',\n",
       "  'удача']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_ans[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['вопрос', 'тдв', 'отдыхать', 'лично', 'советовать', 'завести'],\n",
       " ['парень',\n",
       "  'относиться',\n",
       "  'цветной',\n",
       "  'линза',\n",
       "  'девушка',\n",
       "  'зелёный',\n",
       "  'глаз',\n",
       "  'голубой'],\n",
       " ['делать', 'найти', '2', 'миллион', 'рубль']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_q[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zwXvXkJBVJ0B"
   },
   "outputs": [],
   "source": [
    "# Обучим модель FastText\n",
    "\n",
    "file_path_from = 'ft_model_test'\n",
    "if not os.path.isfile(file_path_from):  \n",
    "    \n",
    "    modelFT = FastText(sentences=sentences_ans, vector_size=100, min_count=1, window=5)\n",
    "    modelFT.save(\"ft_model_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузить модель\n",
    "\n",
    "modelFT = FastText.load(\"ft_model_test\")\n",
    "ft_index = annoy.AnnoyIndex(100 ,'angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_map = {i: ' '.join(sentences_ans[i]) for i in range(0, len(sentences_ans))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'эбу электронный блок управление двигатель автомобиль название контроллер принимать информация датчик обрабатывать особый алгоритм отталкиваться получить данные отдавать команда исполнительный устройство система'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_map[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"index_speaker.pkl\", \"wb\") as f:\n",
    "        pickle.dump(index_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bab729d5b9545ca93673de3c53ff630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создаем Индексы для вопросов-ответов\n",
    "\n",
    "file_path_from = 'speaker.ann'\n",
    "if not os.path.isfile(file_path_from):  \n",
    "    modelFT = FastText.load(\"ft_model_test\")\n",
    "    ft_index = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "    counter = 0\n",
    "      \n",
    "    for sent in tqdm(sentences_q):\n",
    "        n_ft = 0\n",
    "        question = sent\n",
    "        vector_ft = np.zeros(100)\n",
    "        for word in question:\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word]\n",
    "                n_ft += 1\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "    ft_index.build(10)\n",
    "    ft_index.save('speaker.ann')\n",
    "    \n",
    "    #with open(\"index_speaker.pkl\", \"wb\") as f:\n",
    "        #pickle.dump(index_map, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ofHcj4W8VJ0E",
    "outputId": "f40f185c-ae76-4c53-c08f-5428d1745c7b"
   },
   "outputs": [],
   "source": [
    "#  Загрузим индексы\n",
    "ft_index = annoy.AnnoyIndex(100, 'angular')\n",
    "ft_index.load('speaker.ann')\n",
    "index_map = pd.read_pickle(\"index_speaker.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'эбу электронный блок управление двигатель автомобиль название контроллер принимать информация датчик обрабатывать особый алгоритм отталкиваться получить данные отдавать команда исполнительный устройство система'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_map[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 66, 87, 21, 48, 29, 65,  7, 50, 79, 54, 61,  6, 51, 75,  9, 10,\n",
       "       30, 26, 34, 39, 43, 41, 17,  4, 69, 73, 96, 99, 23, 85, 13, 93, 44,\n",
       "        2, 24, 72, 68, 71, 63, 38, 97, 33, 47, 95, 57, 27, 32, 49, 81, 12,\n",
       "       18,  5, 40, 82,  3, 58, 42, 88, 14, 98, 94, 70, 56, 84, 92, 59, 20,\n",
       "       53,  1, 76, 28, 83, 37, 11, 45, 52, 64, 90, 60, 36, 15, 77, 67, 31,\n",
       "       74, 16, 55,  0, 19, 62, 46, 89, 91,  8, 35, 80, 78, 86, 25])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "b9DvlLGVVJ0F",
    "outputId": "27a213d5-372d-428b-de89-0b1f19af8a73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([429649, 356823, 110903],\n",
       " [1.097115397453308, 1.1190354824066162, 1.125589370727539])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Пример получения индексов\n",
    "a = ft_index.get_nns_by_vector(np.random.permutation(100), 3, include_distances=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['педофил надеяться',\n",
       " 'джинсы водолазка',\n",
       " 'ребёнок сын ребёнок любой пол идеали зароботок трое мальчик девочка']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index_map[x] for x in a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gbcdn.mrgcdn.ru/uploads/asset/5209459/attachment/1b2f5aa57ff77e7c2d2ee26ceb09eb9e.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Z-qxfw70VJ0G",
    "outputId": "d9ad78f5-5ed3-4690-e5d4-2d05ba34155c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863bb63631d149489b75eff94afc06ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descrirption</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>subcategory_id</th>\n",
       "      <th>properties</th>\n",
       "      <th>image_links</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Юбка детская ORBY</td>\n",
       "      <td>Новая, не носили ни разу. В реале красивей чем...</td>\n",
       "      <td>58e3cfe6132ca50e053f5f82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2211</td>\n",
       "      <td>{'detskie_razmer_rost': '81-86 (1,5 года)'}</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/58...</td>\n",
       "      <td>[юбка, детский, новый, носить, реал, красивый,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ботильоны</td>\n",
       "      <td>Новые,привезены из Чехии ,указан размер 40,но ...</td>\n",
       "      <td>5667531b2b7f8d127d838c34</td>\n",
       "      <td>9.0</td>\n",
       "      <td>902</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "      <td>[ботильон, новыепривезти, чехия, указать, разм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Брюки</td>\n",
       "      <td>Размер 40-42. Брюки почти новые - не знаю как ...</td>\n",
       "      <td>59534826aaab284cba337e06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>906</td>\n",
       "      <td>{'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/59...</td>\n",
       "      <td>[брюки, размер, 4042, брюки, новый, знать, мер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Продам детские шапки</td>\n",
       "      <td>Продам шапки,кажда 200р.Розовая и белая проданны.</td>\n",
       "      <td>57de544096ad842e26de8027</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2217</td>\n",
       "      <td>{'detskie_pol': 'Девочкам', 'detskaya_odezhda_...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/57...</td>\n",
       "      <td>[продать, детский, шапка, продать, шапкикажда,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Блузка</td>\n",
       "      <td>Темно-синяя, 42 размер,состояние отличное,как ...</td>\n",
       "      <td>5ad4d2626c86cb168d212022</td>\n",
       "      <td>9.0</td>\n",
       "      <td>907</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5a...</td>\n",
       "      <td>[блузка, темносиний, 42, размерсостояние, отли...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                       descrirption  \\\n",
       "0     Юбка детская ORBY  Новая, не носили ни разу. В реале красивей чем...   \n",
       "1             Ботильоны  Новые,привезены из Чехии ,указан размер 40,но ...   \n",
       "2                 Брюки  Размер 40-42. Брюки почти новые - не знаю как ...   \n",
       "3  Продам детские шапки  Продам шапки,кажда 200р.Розовая и белая проданны.   \n",
       "4                Блузка  Темно-синяя, 42 размер,состояние отличное,как ...   \n",
       "\n",
       "                 product_id  category_id subcategory_id  \\\n",
       "0  58e3cfe6132ca50e053f5f82         22.0           2211   \n",
       "1  5667531b2b7f8d127d838c34          9.0            902   \n",
       "2  59534826aaab284cba337e06          9.0            906   \n",
       "3  57de544096ad842e26de8027         22.0           2217   \n",
       "4  5ad4d2626c86cb168d212022          9.0            907   \n",
       "\n",
       "                                          properties  \\\n",
       "0        {'detskie_razmer_rost': '81-86 (1,5 года)'}   \n",
       "1  {'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...   \n",
       "2  {'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...   \n",
       "3  {'detskie_pol': 'Девочкам', 'detskaya_odezhda_...   \n",
       "4  {'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...   \n",
       "\n",
       "                                         image_links  \\\n",
       "0  http://cache3.youla.io/files/images/360_360/58...   \n",
       "1  http://cache3.youla.io/files/images/360_360/5b...   \n",
       "2  http://cache3.youla.io/files/images/360_360/59...   \n",
       "3  http://cache3.youla.io/files/images/360_360/57...   \n",
       "4  http://cache3.youla.io/files/images/360_360/5a...   \n",
       "\n",
       "                                                text  \n",
       "0  [юбка, детский, новый, носить, реал, красивый,...  \n",
       "1  [ботильон, новыепривезти, чехия, указать, разм...  \n",
       "2  [брюки, размер, 4042, брюки, новый, знать, мер...  \n",
       "3  [продать, детский, шапка, продать, шапкикажда,...  \n",
       "4  [блузка, темносиний, 42, размерсостояние, отли...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим модель продуктовых данных\n",
    "\n",
    "shop_data = pd.read_csv(\"ProductsDataset.csv\")\n",
    "#shop_data = shop_data.iloc[:5000, :]\n",
    "\n",
    "shop_data['text'] = shop_data['title'] + \" \" + shop_data[\"descrirption\"]\n",
    "shop_data['text'] = shop_data['text'].progress_apply(lambda x: preprocess_txt(str(x)))\n",
    "shop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "rqml_x5JVJ0H"
   },
   "outputs": [],
   "source": [
    "# Подготовка для создания модели для определения домена данных\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "#vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Xfxh1xO9VJ0I"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea140c51e304269a0ced52a77324105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246000c2f0e54930b275a2ce9f523e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idxs = set(np.random.randint(0, len(index_map), len(shop_data)))\n",
    "# Вопрос-ответный домен\n",
    "negative_texts = [\" \".join(index_map[i]) for i in tqdm(idxs)]\n",
    "# Продуктовый домен\n",
    "positive_texts = [\" \".join(val) for val in tqdm(shop_data['text'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "3ud68payVJ0J"
   },
   "outputs": [],
   "source": [
    "# ВО = 0, Прод = 1\n",
    "\n",
    "dataset = negative_texts + positive_texts\n",
    "labels = np.zeros(len(dataset))\n",
    "labels[len(negative_texts):] = np.ones(len(positive_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "N_oxnOuzVJ0K"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, \n",
    "                                                    stratify=labels, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(ngram_range=(1, 2))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vec = vectorizer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "tNzqfsIZVJ0K",
    "outputId": "d3173275-3a00-47e2-8243-372f61a627c5"
   },
   "outputs": [],
   "source": [
    "# Модель\n",
    "\n",
    "#x_train_vec = vectorizer.transform(X_train)\n",
    "#x_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000).fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "q_bWwksAVJ0L",
    "outputId": "e410d691-e516-45aa-ac0e-d8ef0378cc4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962557273768614"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Качество\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true=y_test, y_pred=lr.predict(x_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим IDF взвешивание (для каждого слова найдем IDF вес)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "XFgbubh7VJ0N"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer().fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "yx8AkUiiVJ0N",
    "outputId": "dce321cc-2846-4c1c-a42e-c6aff189837e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.048852459258441"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tfidf_vect.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "aQQG_bluVJ0O",
    "outputId": "90701b9a-a491-417a-a291-fc3209df90fb"
   },
   "outputs": [],
   "source": [
    "idfs = {v[0]: v[1] for v in zip(tfidf_vect.vocabulary_, tfidf_vect.idf_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41159"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['юбка', 'детский', 'новый', 'носить', 'реал']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(idfs.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.544481321830316,\n",
       " 8.627558709648255,\n",
       " 11.460772053704472,\n",
       " 11.460772053704472,\n",
       " 11.460772053704472]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(idfs.values())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText.load(\"ft_model_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "9ae8735faac34a36be98a6d1f1fcd62e"
     ]
    },
    "id": "JjWyFjJBVJ0P",
    "outputId": "69c1e269-b020-4542-9b84-812cc5485b08"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e37df431324c4a908e0f2f66679246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создаем Индексы для продуктовых данных\n",
    "\n",
    "file_path_from = 'shop.ann'\n",
    "if not os.path.isfile(file_path_from):  \n",
    "    \n",
    "    \n",
    "    ft_index_shop = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "    midf = np.mean(tfidf_vect.idf_)\n",
    "\n",
    "    index_map_shop = {}\n",
    "    counter = 0\n",
    "\n",
    "    for i in tqdm(range(len(shop_data))):\n",
    "        n_ft = 0\n",
    "        index_map_shop[counter] = (shop_data.loc[i, \"title\"], shop_data.loc[i, \"image_links\"])\n",
    "        vector_ft = np.zeros(100)\n",
    "        for word in shop_data.loc[i, \"text\"]:\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word] * idfs.get(word, midf)\n",
    "                n_ft += idfs.get(word, midf)\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "            ft_index_shop.add_item(counter, vector_ft)\n",
    "            counter += 1\n",
    "\n",
    "    ft_index_shop.build(10)\n",
    "    ft_index_shop.save('shop.ann')\n",
    "\n",
    "    file_path_from = 'index_shop.pkl'\n",
    "    if not os.path.isfile(file_path_from):  \n",
    "    \n",
    "        with open(\"index_shop.pkl\", \"wb\") as f:\n",
    "            pickle.dump(index_map_shop, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим индексы\n",
    "\n",
    "midf = np.mean(tfidf_vect.idf_)\n",
    "\n",
    "ft_index_shop = annoy.AnnoyIndex(100, 'angular')\n",
    "ft_index_shop.load('shop.ann') \n",
    "\n",
    "index_map_shop = pd.read_pickle(\"index_shop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "47tviu39VJ0Q"
   },
   "outputs": [],
   "source": [
    "# Основная функция преобразования текста в вектор х100\n",
    "\n",
    "def embed_txt(txt, idfs, midf):\n",
    "    n_ft = 0\n",
    "    vector_ft = np.zeros(100)\n",
    "    for word in txt:\n",
    "        if word in modelFT.wv:\n",
    "            vector_ft += modelFT.wv[word] * idfs.get(word, midf)\n",
    "            n_ft += idfs.get(word, midf)\n",
    "    return vector_ft / n_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def embed_txt(txt, idfs, midf):\n",
    "#     n_ft = 0\n",
    "#     vector_ft = np.zeros(100)\n",
    "#     for word in txt:\n",
    "#         if word in modelFT.wv:\n",
    "#             vector_ft += modelFT.wv[word] * 1 # idfs.get(word, midf)\n",
    "#             n_ft += 1 # idfs.get(word, midf)\n",
    "#     return vector_ft / n_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание своего бота в телеграмм\n",
    "# @botfather\n",
    "# /start\n",
    "# /newbot - create a new bot\n",
    "# name1\n",
    "# name1_BOT\n",
    "#. ->. API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "B3sxuG-hVJ0S",
    "outputId": "e61e1613-8860-4e1a-814a-eda3f75bd6ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9157148003578186\n"
     ]
    }
   ],
   "source": [
    "# заменить на свой токен\n",
    "updater = Updater(\"6228297259:AAHe1et_NeJbuN6-fnzzVV7w2l4L0CJPYpA\", use_context=True) # Токен API к Telegram\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "def startCommand(update, context):\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text='Привет, давай пообщаемся?')\n",
    "\n",
    "def textMessage(update, context):\n",
    "    \n",
    "    input_txt = preprocess_txt(update.message.text)\n",
    "    vect = vectorizer.transform([\" \".join(input_txt)])\n",
    "    prediction = lr.predict(vect)\n",
    "    \n",
    "    # ПРОД\n",
    "    if prediction[0] == 1:\n",
    "        vect_ft = embed_txt(input_txt, idfs, midf)\n",
    "        ft_index_shop_val = ft_index_shop.get_nns_by_vector(vect_ft, 5)\n",
    "        for item in ft_index_shop_val:\n",
    "            title, image = index_map_shop[item]\n",
    "            context.bot.send_message(chat_id=update.message.chat_id, text=\"title: {} image: {}\".format(title, image))\n",
    "        return\n",
    "    \n",
    "    # QA\n",
    "    vect_ft = embed_txt(input_txt, {}, 1)\n",
    "    ft_index_val, distances = ft_index.get_nns_by_vector(vect_ft, 1, include_distances=True)\n",
    "    \n",
    "    # \n",
    "    if distances[0] > 0.9:\n",
    "        print(distances[0])\n",
    "        context.bot.send_message(chat_id=update.message.chat_id, text=\"Моя твоя не понимать\")\n",
    "        return\n",
    "    \n",
    "    # Вопрос-Ответ\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=index_map[ft_index_val[0]])\n",
    "            \n",
    "start_command_handler = CommandHandler('start', startCommand)\n",
    "text_message_handler = MessageHandler(Filters.text, textMessage)\n",
    "dispatcher.add_handler(start_command_handler)\n",
    "dispatcher.add_handler(text_message_handler)\n",
    "updater.start_polling(clean=True)\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "lesson_16.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
